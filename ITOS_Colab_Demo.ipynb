{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ ITOS - Intraday Trading Operating System (Google Colab Edition)\n",
    "\n",
    "## Complete Workflow on Google Colab\n",
    "\n",
    "This notebook demonstrates the complete ITOS workflow on Google Colab:\n",
    "1. **Mount Google Drive** and setup environment\n",
    "2. **Convert Kaggle data** to Parquet format\n",
    "3. **Run trading strategies** across all symbols\n",
    "4. **Analyze performance** with comprehensive metrics\n",
    "5. **Generate visualizations** and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install pandas numpy pyarrow matplotlib seaborn tqdm kagglehub\n",
    "!pip install --upgrade google-api-python-client google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and setup environment\n",
    "from google.colab import drive\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Mount Google Drive\n",
    "print(\"ğŸ”— Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Setup paths\n",
    "DRIVE_BASE = \"/content/drive/MyDrive/itos\"\n",
    "DATA_DIR = f\"{DRIVE_BASE}/minute_parquet\"\n",
    "RESULTS_DIR = f\"{DRIVE_BASE}/STR_results\"\n",
    "ANALYTICS_DIR = f\"{DRIVE_BASE}/analytics\"\n",
    "LOGS_DIR = f\"{DRIVE_BASE}/logs\"\n",
    "\n",
    "# Create directories\n",
    "for directory in [DATA_DIR, RESULTS_DIR, ANALYTICS_DIR, LOGS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Google Drive mounted and directories created\")\n",
    "print(f\"ğŸ“ Base Directory: {DRIVE_BASE}\")\n",
    "\n",
    "# Add project to Python path\n",
    "sys.path.insert(0, DRIVE_BASE)\n",
    "\n",
    "print(\"ğŸ¯ Environment setup completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download and Convert Kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Kaggle dataset\n",
    "import kagglehub\n",
    "\n",
    "DATASET = \"debashis74017/algo-trading-data-nifty-100-data-with-indicators\"\n",
    "print(\"ğŸ“¥ Downloading Kaggle dataset...\")\n",
    "\n",
    "path = kagglehub.dataset_download(DATASET)\n",
    "print(f\"ğŸ“ Dataset downloaded at: {path}\")\n",
    "\n",
    "# List downloaded files\n",
    "import os\n",
    "print(f\"ğŸ“‹ Files in dataset: {len(os.listdir(path))}\")\n",
    "print(f\"ğŸ“„ Sample files: {os.listdir(path)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSV data to Parquet format\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SOURCE_DIR = path\n",
    "TARGET_DIR = DATA_DIR\n",
    "\n",
    "# Get list of CSV files\n",
    "csv_files = sorted([f for f in os.listdir(SOURCE_DIR) if f.endswith(\"_minute.csv\")])\n",
    "print(f\"ğŸ“Š Found {len(csv_files)} CSV files to convert\")\n",
    "\n",
    "# Check existing files\n",
    "existing_files = set([f.replace('.parquet', '') for f in os.listdir(TARGET_DIR) if f.endswith('.parquet')])\n",
    "files_to_convert = [f.replace('_minute.csv', '') for f in csv_files if f.replace('_minute.csv', '') not in existing_files]\n",
    "\n",
    "print(f\"ğŸ“ˆ Files to convert: {len(files_to_convert)}\")\n",
    "print(f\"â­ Already converted: {len(existing_files)}\")\n",
    "\n",
    "def detect_timestamp_column(df):\n",
    "    \"\"\"Detect timestamp column in DataFrame.\"\"\"\n",
    "    timestamp_columns = ['timestamp', 'datetime', 'date', 'Date', 'time', 'Time']\n",
    "    for col in timestamp_columns:\n",
    "        if col in df.columns:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def process_csv_to_parquet(csv_file, symbol):\n",
    "    \"\"\"Process a single CSV file to Parquet format.\"\"\"\n",
    "    try:\n",
    "        csv_path = os.path.join(SOURCE_DIR, csv_file)\n",
    "        parquet_path = os.path.join(TARGET_DIR, f\"{symbol}.parquet\")\n",
    "        \n",
    "        # Read CSV in chunks\n",
    "        chunks = []\n",
    "        chunk_size = 10000\n",
    "        \n",
    "        for chunk in pd.read_csv(csv_path, chunksize=chunk_size, low_memory=False):\n",
    "            # Detect timestamp column\n",
    "            ts_col = detect_timestamp_column(chunk)\n",
    "            if ts_col is None:\n",
    "                print(f\"âš ï¸ No timestamp column found for {symbol}\")\n",
    "                return False\n",
    "            \n",
    "            # Rename and convert timestamp\n",
    "            chunk = chunk.rename(columns={ts_col: 'timestamp'})\n",
    "            chunk['timestamp'] = pd.to_datetime(chunk['timestamp'], errors='coerce')\n",
    "            \n",
    "            # Remove invalid rows\n",
    "            chunk = chunk.dropna(subset=['timestamp'])\n",
    "            chunk = chunk.sort_values('timestamp')\n",
    "            \n",
    "            # Filter trading hours\n",
    "            chunk['time'] = chunk['timestamp'].dt.time\n",
    "            trading_hours = (\n",
    "                (chunk['time'] >= pd.Timestamp('09:15').time()) & \n",
    "                (chunk['time'] <= pd.Timestamp('15:30').time())\n",
    "            )\n",
    "            chunk = chunk[trading_hours].drop('time', axis=1)\n",
    "            \n",
    "            # Standardize columns\n",
    "            chunk.columns = chunk.columns.str.lower().str.replace(' ', '_')\n",
    "            \n",
    "            # Map required columns\n",
    "            column_mapping = {\n",
    "                'open': 'open', 'high': 'high', 'low': 'low', 'close': 'close', 'volume': 'volume'\n",
    "            }\n",
    "            \n",
    "            for old_name, new_name in column_mapping.items():\n",
    "                if old_name in chunk.columns:\n",
    "                    chunk = chunk.rename(columns={old_name: new_name})\n",
    "            \n",
    "            # Check required columns\n",
    "            required_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "            if not all(col in chunk.columns for col in required_cols):\n",
    "                print(f\"âš ï¸ Missing required columns for {symbol}\")\n",
    "                return False\n",
    "            \n",
    "            # Add basic features\n",
    "            chunk['returns'] = chunk['close'].pct_change()\n",
    "            chunk['typical_price'] = (chunk['high'] + chunk['low'] + chunk['close']) / 3\n",
    "            chunk['range'] = chunk['high'] - chunk['low']\n",
    "            chunk['body'] = abs(chunk['close'] - chunk['open'])\n",
    "            \n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        if not chunks:\n",
    "            print(f\"âš ï¸ No valid data for {symbol}\")\n",
    "            return False\n",
    "        \n",
    "        # Combine chunks and save\n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "        df.to_parquet(parquet_path, compression='snappy', index=False)\n",
    "        \n",
    "        del df, chunks\n",
    "        gc.collect()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing {symbol}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Convert files (with progress bar)\n",
    "successful = []\n",
    "failed = []\n",
    "\n",
    "for i, symbol in enumerate(tqdm(files_to_convert, desc=\"Converting files\")):\n",
    "    csv_file = f\"{symbol}_minute.csv\"\n",
    "    \n",
    "    if process_csv_to_parquet(csv_file, symbol):\n",
    "        successful.append(symbol)\n",
    "    else:\n",
    "        failed.append(symbol)\n",
    "    \n",
    "    # Memory cleanup\n",
    "    if i % 10 == 0:\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"\\nğŸ‰ Conversion completed:\")\n",
    "print(f\"   âœ… Successful: {len(successful)}\")\n",
    "print(f\"   âŒ Failed: {len(failed)}\")\n",
    "print(f\"   ğŸ“Š Total processed: {len(successful) + len(existing_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load ITOS System and Run Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ITOS modules\n",
    "from itos_colab.core.data_engine import ColabDataEngine\n",
    "from itos_colab.core.strategy_engine import ColabStrategyEngine\n",
    "from itos_colab.core.analytics_engine import ColabAnalyticsEngine\n",
    "from itos_colab.strategies.str001_orb import STR001_ORB\n",
    "from itos_colab.strategies.str002_orb_filtered import STR002_ORB_FILTERED\n",
    "from itos_colab.strategies.str003_vwap_pullback import STR003_VWAP_PULLBACK\n",
    "\n",
    "print(\"âœ… ITOS modules imported successfully\")\n",
    "\n",
    "# Initialize data engine and get summary\n",
    "data_engine = ColabDataEngine()\n",
    "summary = data_engine.get_data_summary()\n",
    "\n",
    "print(f\"\\nğŸ“Š Data Summary:\")\n",
    "print(f\"   Symbols: {summary.get('symbols', 0)}\")\n",
    "print(f\"   Records: {summary.get('total_records', 0):,}\")\n",
    "print(f\"   Date Range: {summary.get('date_range', ('N/A', 'N/A'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data for one symbol\n",
    "symbols = data_engine.get_processed_symbols()\n",
    "\n",
    "if symbols:\n",
    "    test_symbol = symbols[0]\n",
    "    market_data = data_engine.load_symbol_data(test_symbol)\n",
    "    \n",
    "    if market_data:\n",
    "        print(f\"ğŸ“ˆ Sample data for {test_symbol}:\")\n",
    "        print(f\"   Shape: {market_data.data.shape}\")\n",
    "        print(f\"   Columns: {list(market_data.data.columns)}\")\n",
    "        print(f\"   Date range: {market_data.data['timestamp'].min()} to {market_data.data['timestamp'].max()}\")\n",
    "        \n",
    "        # Display sample data\n",
    "        display(market_data.data.head())\n",
    "        \n",
    "        # Plot price chart\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(market_data.data['timestamp'], market_data.data['close'])\n",
    "        plt.title(f'{test_symbol} - Price Chart')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.grid(True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"âŒ No data found for {test_symbol}\")\n",
    "else:\n",
    "    print(\"âŒ No symbols found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run Trading Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize strategy engine\n",
    "strategy_engine = ColabStrategyEngine()\n",
    "\n",
    "# Define strategies to run\n",
    "strategies = [\n",
    "    STR001_ORB(),\n",
    "    STR002_ORB_FILTERED(),\n",
    "    STR003_VWAP_PULLBACK()\n",
    "]\n",
    "\n",
    "print(f\"ğŸš€ Running {len(strategies)} strategies...\")\n",
    "\n",
    "# Get symbols to process\n",
    "symbols = data_engine.get_processed_symbols()\n",
    "print(f\"ğŸ“Š Available symbols: {len(symbols)}\")\n",
    "\n",
    "# For testing, limit to first 20 symbols (remove this for full run)\n",
    "# symbols = symbols[:20]\n",
    "# print(f\"ğŸ§ª Testing with first {len(symbols)} symbols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each strategy\n",
    "results = []\n",
    "\n",
    "for strategy in strategies:\n",
    "    strategy_name = strategy.get_config().name\n",
    "    print(f\"\\nğŸ“ˆ Running {strategy_name}...\")\n",
    "    \n",
    "    # Run strategy\n",
    "    success = strategy_engine.run_strategy(strategy, symbols)\n",
    "    \n",
    "    if success:\n",
    "        # Load and display results\n",
    "        trades_df = strategy_engine.get_strategy_results(strategy_name)\n",
    "        \n",
    "        if trades_df is not None and not trades_df.empty:\n",
    "            print(f\"   âœ… {strategy_name} completed with {len(trades_df)} trades\")\n",
    "            \n",
    "            # Basic statistics\n",
    "            total_pnl = trades_df['pnl'].sum()\n",
    "            winning_trades = len(trades_df[trades_df['pnl'] > 0])\n",
    "            win_rate = winning_trades / len(trades_df) * 100\n",
    "            \n",
    "            print(f\"   ğŸ“Š Total PnL: â‚¹{total_pnl:,.2f}\")\n",
    "            print(f\"   ğŸ¯ Win Rate: {win_rate:.1f}%\")\n",
    "            print(f\"   ğŸ“ˆ Symbols: {trades_df['symbol'].nunique()}\")\n",
    "            \n",
    "            # Display sample trades\n",
    "            print(f\"   ğŸ“‹ Sample trades:\")\n",
    "            display(trades_df.head())\n",
    "            \n",
    "            results.append({\n",
    "                'strategy': strategy_name,\n",
    "                'trades': len(trades_df),\n",
    "                'pnl': total_pnl,\n",
    "                'win_rate': win_rate,\n",
    "                'symbols': trades_df['symbol'].nunique()\n",
    "            })\n",
    "        else:\n",
    "            print(f\"   âš ï¸ {strategy_name} completed but no trades generated\")\n",
    "    else:\n",
    "        print(f\"   âŒ {strategy_name} failed\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"\\nğŸ‰ Strategy execution completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Analytics and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize analytics engine\n",
    "analytics_engine = ColabAnalyticsEngine()\n",
    "\n",
    "print(f\"ğŸ“Š Running comprehensive analytics...\")\n",
    "\n",
    "# Analyze each strategy\n",
    "detailed_results = []\n",
    "\n",
    "for strategy in strategies:\n",
    "    strategy_name = strategy.get_config().name\n",
    "    print(f\"\\nğŸ” Analyzing {strategy_name}...\")\n",
    "    \n",
    "    # Load trades\n",
    "    trades_df = strategy_engine.get_strategy_results(strategy_name)\n",
    "    \n",
    "    if trades_df is not None and not trades_df.empty:\n",
    "        # Run comprehensive analytics\n",
    "        result = analytics_engine.analyze_strategy(strategy_name, trades_df)\n",
    "        detailed_results.append(result)\n",
    "        \n",
    "        # Print detailed results\n",
    "        print(f\"\\nğŸ“‹ {strategy_name} Detailed Analytics:\")\n",
    "        print(f\"   Total Trades: {result.total_trades}\")\n",
    "        print(f\"   Winning Trades: {result.winning_trades}\")\n",
    "        print(f\"   Losing Trades: {result.losing_trades}\")\n",
    "        print(f\"   Total PnL: â‚¹{result.total_pnl:,.2f}\")\n",
    "        print(f\"   Max Drawdown: {result.max_drawdown*100:.2f}%\")\n",
    "        print(f\"   Profit Factor: {result.profit_factor:.2f}\")\n",
    "        print(f\"   Sharpe Ratio: {result.sharpe_ratio:.2f}\")\n",
    "        print(f\"   Avg Duration: {result.avg_trade_duration:.1f} minutes\")\n",
    "        \n",
    "        # Get recommendation\n",
    "        recommendation = analytics_engine.evaluate_strategy(result)\n",
    "        print(f\"   Recommendation: {recommendation}\")\n",
    "        \n",
    "        if recommendation == \"APPROVE\":\n",
    "            print(\"   âœ… Strategy approved for live trading\")\n",
    "        elif recommendation == \"MODIFY\":\n",
    "            print(\"   âš ï¸ Strategy needs modification\")\n",
    "        else:\n",
    "            print(\"   âŒ Strategy killed - not viable\")\n",
    "        \n",
    "        # Display additional insights\n",
    "        if result.metadata:\n",
    "            print(f\"\\nğŸ’¡ Additional Insights:\")\n",
    "            \n",
    "            if 'win_rate_analysis' in result.metadata:\n",
    "                win_data = result.metadata['win_rate_analysis']\n",
    "                print(f\"   Overall Win Rate: {win_data['overall_win_rate']*100:.1f}%\")\n",
    "                print(f\"   Symbol Avg Win Rate: {win_data['symbol_avg_win_rate']*100:.1f}%\")\n",
    "            \n",
    "            if 'risk_metrics' in result.metadata:\n",
    "                risk_data = result.metadata['risk_metrics']\n",
    "                print(f\"   VaR (95%): â‚¹{risk_data.get('var_95', 0):,.2f}\")\n",
    "                print(f\"   Max Consecutive Losses: {risk_data.get('max_consecutive_losses', 0)}\")\n",
    "                print(f\"   Avg Win/Loss Ratio: {risk_data.get('avg_win_to_loss_ratio', 0):.2f}\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ No trades found for {strategy_name}\")\n",
    "    \n",
    "    # Memory cleanup\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Strategy Comparison and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare strategies\n",
    "if detailed_results:\n",
    "    strategy_names = [r.strategy_name for r in detailed_results]\n",
    "    comparison_df = analytics_engine.compare_strategies(strategy_names)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Strategy Performance Comparison:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Create comparison charts\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Strategy Comparison Dashboard', fontsize=16)\n",
    "    \n",
    "    # Total PnL comparison\n",
    "    axes[0, 0].bar(comparison_df['Strategy'], comparison_df['Total PnL'])\n",
    "    axes[0, 0].set_title('Total PnL')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Win Rate comparison\n",
    "    axes[0, 1].bar(comparison_df['Strategy'], comparison_df['Win Rate'] * 100)\n",
    "    axes[0, 1].set_title('Win Rate (%)')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Profit Factor comparison\n",
    "    axes[1, 0].bar(comparison_df['Strategy'], comparison_df['Profit Factor'])\n",
    "    axes[1, 0].set_title('Profit Factor')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Sharpe Ratio comparison\n",
    "    axes[1, 1].bar(comparison_df['Strategy'], comparison_df['Sharpe Ratio'])\n",
    "    axes[1, 1].set_title('Sharpe Ratio')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display best strategy\n",
    "    best_strategy = comparison_df.iloc[0]\n",
    "    print(f\"\\nğŸ† Best Strategy: {best_strategy['Strategy']}\")\n",
    "    print(f\"   Total PnL: â‚¹{best_strategy['Total PnL']:,.2f}\")\n",
    "    print(f\"   Win Rate: {best_strategy['Win Rate']*100:.1f}%\")\n",
    "    print(f\"   Profit Factor: {best_strategy['Profit Factor']:.2f}\")\n",
    "    print(f\"   Sharpe Ratio: {best_strategy['Sharpe Ratio']:.2f}\")\n",
    "else:\n",
    "    print(\"âŒ No strategy results to compare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Detailed Analysis of Best Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze best performing strategy in detail\n",
    "if detailed_results:\n",
    "    # Find best strategy by total PnL\n",
    "    best_result = max(detailed_results, key=lambda x: x.total_pnl)\n",
    "    best_strategy_name = best_result.strategy_name\n",
    "    \n",
    "    print(f\"\\nğŸ† Detailed Analysis of Best Strategy: {best_strategy_name}\")\n",
    "    print(f\"   Total PnL: â‚¹{best_result.total_pnl:,.2f}\")\n",
    "    \n",
    "    # Load trades for detailed analysis\n",
    "    trades_df = strategy_engine.get_strategy_results(best_strategy_name)\n",
    "    \n",
    "    if trades_df is not None and not trades_df.empty:\n",
    "        # Convert datetime columns\n",
    "        trades_df['entry_time'] = pd.to_datetime(trades_df['entry_time'])\n",
    "        trades_df['exit_time'] = pd.to_datetime(trades_df['exit_time'])\n",
    "        \n",
    "        # Monthly performance\n",
    "        trades_df['entry_month'] = trades_df['entry_time'].dt.to_period('M')\n",
    "        monthly_stats = trades_df.groupby('entry_month').agg({\n",
    "            'pnl': ['count', 'sum', 'mean'],\n",
    "            'symbol': 'nunique'\n",
    "        }).round(2)\n",
    "        \n",
    "        print(f\"\\nğŸ“… Monthly Performance:\")\n",
    "        monthly_stats.columns = ['Trades', 'Total PnL', 'Avg PnL', 'Symbols']\n",
    "        display(monthly_stats)\n",
    "        \n",
    "        # Symbol performance\n",
    "        symbol_stats = trades_df.groupby('symbol').agg({\n",
    "            'pnl': ['count', 'sum', 'mean']\n",
    "        }).round(2)\n",
    "        \n",
    "        symbol_stats.columns = ['Trades', 'Total PnL', 'Avg PnL']\n",
    "        symbol_stats = symbol_stats.sort_values('Total PnL', ascending=False)\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Top Performing Symbols (Top 10):\")\n",
    "        display(symbol_stats.head(10))\n",
    "        \n",
    "        # Exit reason analysis\n",
    "        exit_reason_stats = trades_df.groupby('exit_reason').agg({\n",
    "            'pnl': ['count', 'sum', 'mean'],\n",
    "        }).round(2)\n",
    "        \n",
    "        exit_reason_stats.columns = ['Count', 'Total PnL', 'Avg PnL']\n",
    "        \n",
    "        print(f\"\\nğŸšª Exit Reason Analysis:\")\n",
    "        display(exit_reason_stats)\n",
    "        \n",
    "        # Plot equity curve\n",
    "        trades_df_sorted = trades_df.sort_values('entry_time')\n",
    "        trades_df_sorted['cumulative_pnl'] = trades_df_sorted['pnl'].cumsum()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(trades_df_sorted['entry_time'], trades_df_sorted['cumulative_pnl'])\n",
    "        plt.title(f'{best_strategy_name} - Equity Curve')\n",
    "        plt.ylabel('Cumulative PnL')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Plot drawdown\n",
    "        plt.subplot(2, 1, 2)\n",
    "        trades_df_sorted['running_max'] = trades_df_sorted['cumulative_pnl'].expanding().max()\n",
    "        trades_df_sorted['drawdown'] = trades_df_sorted['cumulative_pnl'] - trades_df_sorted['running_max']\n",
    "        \n",
    "        plt.fill_between(trades_df_sorted['entry_time'], trades_df_sorted['drawdown'], 0, \n",
    "                         color='red', alpha=0.3)\n",
    "        plt.plot(trades_df_sorted['entry_time'], trades_df_sorted['drawdown'], 'r-', label='Drawdown')\n",
    "        plt.title('Drawdown')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Drawdown')\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"âŒ No strategy results available for detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ ITOS Google Colab Execution Completed!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# System summary\n",
    "print(f\"\\nğŸ“Š System Summary:\")\n",
    "print(f\"   ğŸ“ Google Drive Base: {DRIVE_BASE}\")\n",
    "print(f\"   ğŸ“ˆ Processed Symbols: {len(symbols)}\")\n",
    "print(f\"   ğŸ¯ Strategies Tested: {len(strategies)}\")\n",
    "print(f\"   ğŸ“Š Analytics Generated: {len(detailed_results)}\")\n",
    "\n",
    "if detailed_results:\n",
    "    # Strategy summary\n",
    "    print(f\"\\nğŸ“ˆ Strategy Results:\")\n",
    "    for result in detailed_results:\n",
    "        recommendation = analytics_engine.evaluate_strategy(result)\n",
    "        status = \"âœ…\" if recommendation == \"APPROVE\" else \"âš ï¸\" if recommendation == \"MODIFY\" else \"âŒ\"\n",
    "        print(f\"   {status} {result.strategy_name}: â‚¹{result.total_pnl:,.2f} ({result.total_trades} trades)\")\n",
    "    \n",
    "    # Best strategy\n",
    "    best_result = max(detailed_results, key=lambda x: x.total_pnl)\n",
    "    print(f\"\\nğŸ† Best Strategy: {best_result.strategy_name}\")\n",
    "    print(f\"   Total PnL: â‚¹{best_result.total_pnl:,.2f}\")\n",
    "    print(f\"   Win Rate: {best_result.winning_trades/best_result.total_trades*100:.1f}%\")\n",
    "    print(f\"   Profit Factor: {best_result.profit_factor:.2f}\")\n",
    "    print(f\"   Sharpe Ratio: {best_result.sharpe_ratio:.2f}\")\n",
    "\n",
    "# File locations\n",
    "print(f\"\\nğŸ“ Generated Files on Google Drive:\")\n",
    "print(f\"   ğŸ“Š Data: {DATA_DIR}\")\n",
    "print(f\"   ğŸ“ˆ Results: {RESULTS_DIR}\")\n",
    "print(f\"   ğŸ“‹ Analytics: {ANALYTICS_DIR}\")\n",
    "print(f\"   ğŸ“„ Logs: {LOGS_DIR}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Next Steps:\")\n",
    "print(f\"   1. ğŸ“Š Review detailed analytics in Google Drive\")\n",
    "print(f\"   2. ğŸ“ˆ Examine strategy dashboards (PNG files)\")\n",
    "print(f\"   3. ğŸ”§ Modify/kill strategies based on performance\")\n",
    "print(f\"   4. ğŸš€ Develop new strategies using the framework\")\n",
    "print(f\"   5. ğŸ“ˆ Test with additional market data\")\n",
    "print(f\"   6. ğŸ”„ Implement Phase 3 - Strategy Library\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Key Features Used:\")\n",
    "print(f\"   âœ… Google Drive persistence\")\n",
    "print(f\"   âœ… Resume-safe processing\")\n",
    "print(f\"   âœ… Memory-efficient batch processing\")\n",
    "print(f\"   âœ… Comprehensive analytics\")\n",
    "print(f\"   âœ… Interactive visualization\")\n",
    "print(f\"   âœ… Strategy comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ Ready for production use!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}